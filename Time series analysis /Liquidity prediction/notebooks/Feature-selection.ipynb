{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format='retina'\n",
    "plt.rcParams[\"figure.dpi\"] = 70\n",
    "\n",
    "base_dir = Path().resolve().parent\n",
    "data_dir = base_dir / 'data'\n",
    "sys.path.append(str(base_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_dir / 'finalFeatures.csv', index_col=0)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "data = data.drop(columns=['Income', 'Outcome'])\n",
    "target = 'Balance'\n",
    "features = list(data.drop(columns=target).columns)\n",
    "X, y = data[features], data[target]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Built-In Feature Selection Methods: L1 and L2 Regularizations\n",
    "\n",
    "In feature selection, automatic methods are commonly used to select relevant features during the training of a model. Two popular approaches for feature selection are L1 and L2 regularizations.\n",
    "\n",
    "L1 regularization, also known as Lasso regularization, encourages sparsity in the feature space by penalizing the absolute magnitude of the coefficients. This promotes the selection of a subset of features that have the most impact on the model's performance.\n",
    "\n",
    "L2 regularization, also called Ridge regularization, penalizes the squared magnitude of the coefficients. While it also helps in feature selection by shrinking less important features towards zero, it does not promote sparsity as strongly as L1 regularization.\n",
    "\n",
    "When Choosing the Main Model\n",
    "\n",
    "When selecting the main model for your task, it is important to consider the feature selection method that best suits your specific requirements. L1 and L2 regularizations can be integrated into various machine learning models, such as linear regression, logistic regression, and support vector machines, among others.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM and L2 Regularization\n",
    "\n",
    "Support Vector Machines (SVM) is a popular machine learning algorithm that has L2 regularization built into its default implementation. The regularization strength in SVM is controlled by the parameter C, where higher values of C correspond to a lower regularization effect.\n",
    "\n",
    "L2 regularization in SVM helps in controlling the model's complexity by adding a penalty term to the objective function. This penalty discourages large coefficient values and promotes a smoother decision boundary. It helps to prevent overfitting and improve the generalization ability of the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "model = SVR(C=1)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Using SequentialFeatureSelector for Stability Enhancement\n",
    "\n",
    "In order to improve the stability of our method, we will employ the Wrapper method known as SequentialFeatureSelector. This approach helps to select a subset of features by iteratively adding or removing them based on their performance with the chosen model.\n",
    "\n",
    "To ensure reliable evaluation, we will incorporate cross-validation while utilizing the SequentialFeatureSelector. However, traditional cross-validation techniques may not be suitable for time series data due to the temporal nature of the data. Therefore, we will employ a specialized time series split to overcome this challenge.\n",
    "\n",
    "Standard cross-validation, which randomly shuffles the data, can introduce data leakage and provide inaccurate performance estimates when working with time series data. To address this, we will use a specialized time series cross-validation approach such as \"rolling window\" or \"walk-forward\" validation. This method involves sequentially splitting the data into training and validation sets, preserving the temporal order of the data.\n",
    "\n",
    "By incorporating the SequentialFeatureSelector and time series cross-validation, we aim to enhance the stability and reliability of our feature selection process in the context of time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "for i, (train, test) in enumerate(tscv.split(data)):\n",
    "    bar = plt.barh(f'Fold {i}', train.shape[0], color='tab:orange')\n",
    "    plt.bar_label(bar, labels=['train'], label_type='center')\n",
    "\n",
    "    bar = plt.barh(f'Fold {i}', test.shape[0], left=train.shape[0], color='tab:blue')\n",
    "    plt.bar_label(bar, labels=['test'], label_type='center')\n",
    "\n",
    "plt.title('Folds with TimeSeriesSplit')\n",
    "plt.xlabel('Time series observations indexes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR()\n",
    "n_splits = 3\n",
    "sfs = SequentialFeatureSelector(model, cv=TimeSeriesSplit(n_splits), n_features_to_select=15, n_jobs=-1)\n",
    "%time sfs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_mask = sfs.get_support()\n",
    "selected_features = X.columns[selected_features_mask]\n",
    "print('Seleted Features:\\n')\n",
    "print(*selected_features, sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Correlation-based Feature Selection: A Filtering Method\n",
    "\n",
    "In our feature selection process, we will utilize the filtering method known as Correlation-based Feature Selection. This method aims to identify and select relevant features based on their correlation with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslib.feature_selection import get_best_cfs_features\n",
    "\n",
    "print(get_best_cfs_features.__doc__)\n",
    "selected_features, _ = get_best_cfs_features(data, features, target)\n",
    "print('Selected features:\\n')\n",
    "print(*selected_features, sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compare stability of feature selection methods "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Assessing Stability through Metric Variability Across Folds\n",
    "\n",
    "In order to evaluate the stability of our feature selection models, we will examine the variability of metrics when testing on different folds. This approach allows us to assess the consistency of our model's performance across different subsets of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from tslib.scoring import get_score\n",
    "from tslib.feature_selection import fit_default_model, fit_sfs_model, fit_cfs_model\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "metric_dict = defaultdict(list)\n",
    "\n",
    "for train_idx, test_idx in tqdm(list(tscv.split(data))):\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "    for method in ['default', 'sfs', 'cfs']:\n",
    "        fit_func = globals()[f'fit_{method}_model']\n",
    "        current_model, selected_features = fit_func(model, X_train, y_train)\n",
    "\n",
    "        pred = current_model.predict(X_test[selected_features])\n",
    "        score = get_score(y_test, pred)\n",
    "        metric_dict[method].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (method, vals) in enumerate(metric_dict.items()):\n",
    "    plt.scatter([i]*len(vals), vals, label=method)\n",
    "\n",
    "plt.xticks([])\n",
    "plt.legend(bbox_to_anchor=(0.5, 0), loc='upper center', ncol=3)\n",
    "plt.title('Metrics on different folds with different feature selection models');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>sfs</th>\n",
       "      <th>cfs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.70</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.06</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      default   sfs   cfs\n",
       "mean    -0.70 -0.91 -1.03\n",
       "std      1.06  1.15  0.82"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_summary = pd.DataFrame(index=['mean', 'std'])\n",
    "for method, vals in metric_dict.items():\n",
    "    mean = np.mean(vals).round(2)\n",
    "    std = np.std(vals).round(2)\n",
    "    fs_summary[method] = [mean, std]\n",
    "\n",
    "fs_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
